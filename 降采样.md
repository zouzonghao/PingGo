# PingGo 数据存储优化方案

## 目标

解决心跳数据（Heartbeat）随时间无限增长的问题，实现分层存储策略，在保证近期数据精度的同时，大幅降低长期存储成本。

---

## 核心问题分析

当前项目存在以下数据存储问题：

| 问题 | 影响 |
|------|------|
| 心跳数据每 20-60 秒产生一条 | 每个监控每天约 1440-4320 条记录 |
| 虽有 30 天清理机制，但未做降采样 | 30 天数据量仍可达百万级 |
| 长周期查询需要扫描大量细粒度数据 | 查询性能受影响 |

---

## 数据层级架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        数据层级架构                              │
├─────────────────────────────────────────────────────────────────┤
│  Layer 1: 原始数据 (Heartbeat)                                   │
│  - 粒度: 每次检查 (20-60秒)                                       │
│  - 保留: 24小时 (可配置)                                          │
│  - 用途: 实时监控、即时告警、详细故障分析                            │
├─────────────────────────────────────────────────────────────────┤
│  Layer 2: 小时聚合 (HeartbeatHourly)                             │
│  - 粒度: 1小时                                                    │
│  - 保留: 7天 (可配置)                                             │
│  - 用途: 24小时图表、短期趋势分析                                   │
├─────────────────────────────────────────────────────────────────┤
│  Layer 3: 日聚合 (HeartbeatDaily)                                │
│  - 粒度: 1天                                                      │
│  - 保留: 365天 (可配置)                                           │
│  - 用途: 7天图表、月报表、SLA计算、长期趋势                          │
└─────────────────────────────────────────────────────────────────┘
```

---

## 数据量对比

以 10 个监控、60 秒间隔为例：

| 存储策略 | 每天数据量 | 30天数据量 | 一年数据量 |
|---------|-----------|-----------|-----------|
| 原方案（不降采样） | 14,400 条 | 432,000 条 | ~5,260,000 条 |
| 优化方案（分层） | 14,400 + 240 + 10 条 | 7,200 + 240 + 10 条 | 8,760 + 3,650 条 |
| **节省比例** | - | **约 98.3%** | **约 99.8%** |

> **注意**: 原始数据仅保留 24 小时，超过 24 小时后查询小时级聚合数据，超过 7 天后查询天级聚合数据。

---

## 当前实现逻辑

### 一、数据模型

#### 1. 原始心跳数据 (Heartbeat)

```go
type Heartbeat struct {
    ID        uint      `gorm:"primaryKey" json:"id"`
    MonitorID uint      `gorm:"index:idx_monitor_time" json:"monitorID"`
    Status    int       `json:"status"` // 0: DOWN, 1: UP, 2: PENDING, 3: MAINTENANCE
    Message   string    `json:"msg"`
    Time      time.Time `gorm:"index:idx_monitor_time" json:"time"`
    Duration  int       `json:"duration"` // 响应时间 (ms)
}
```

#### 2. 小时聚合数据 (HeartbeatHourly)

```go
type HeartbeatHourly struct {
    ID        uint      `gorm:"primaryKey" json:"id"`
    MonitorID uint      `gorm:"index:idx_hourly_monitor_time" json:"monitorID"`
    Hour      time.Time `gorm:"index:idx_hourly_monitor_time" json:"hour"` // 整点时间

    // 状态统计
    UpCount    int `json:"upCount"`    // UP 次数
    DownCount  int `json:"downCount"`  // DOWN 次数
    TotalCount int `json:"totalCount"` // 总检查次数

    // 响应时间统计 (毫秒) - 只统计成功响应
    SumDuration int `json:"sumDuration"` // 成功响应的延迟总和，用于加权平均计算
    AvgDuration int `json:"avgDuration"` // 平均响应时间
    MinDuration int `json:"minDuration"` // 最小响应时间
    MaxDuration int `json:"maxDuration"` // 最大响应时间

    // 可用率 (0-10000 表示 0.00%-100.00%，使用int节省空间)
    Uptime int `json:"uptime"`
}
```

#### 3. 日聚合数据 (HeartbeatDaily)

```go
type HeartbeatDaily struct {
    ID        uint      `gorm:"primaryKey" json:"id"`
    MonitorID uint      `gorm:"index:idx_daily_monitor_time" json:"monitorID"`
    Date      time.Time `gorm:"index:idx_daily_monitor_time" json:"date"` // 日期 (00:00:00)

    // 状态统计
    UpCount    int `json:"upCount"`
    DownCount  int `json:"downCount"`
    TotalCount int `json:"totalCount"`

    // 响应时间统计 (毫秒) - 只统计成功响应
    SumDuration int `json:"sumDuration"` // 成功响应的延迟总和
    AvgDuration int `json:"avgDuration"`
    MinDuration int `json:"minDuration"`
    MaxDuration int `json:"maxDuration"`

    // 可用率 (0-10000 表示 0.00%-100.00%)
    Uptime int `json:"uptime"`
}
```

### 二、聚合任务 (aggregation.go)

定时任务每小时执行一次，包含以下步骤：

1. **小时聚合** (`aggregateHourly`)
   - 将上一个完整小时内的原始心跳数据聚合为一条 `HeartbeatHourly` 记录
   - 聚合逻辑：
     - `UpCount` = 该小时内 status=1 的记录数
     - `DownCount` = 该小时内 status=0 的记录数
     - `TotalCount` = 该小时内总记录数
     - `SumDuration` = **只统计成功响应(status=1)的延迟总和**
     - `AvgDuration` = SumDuration / UpCount（只基于成功响应）
     - `MinDuration` = 成功响应中的最小延迟
     - `MaxDuration` = 成功响应中的最大延迟
     - `Uptime` = UpCount * 10000 / TotalCount（0-10000 表示 0.00%-100.00%）

2. **日聚合** (`aggregateDaily`)
   - 将昨天的 24 条小时聚合数据进一步聚合为一条 `HeartbeatDaily` 记录
   - 聚合逻辑：
     - `UpCount` = SUM(各小时的 UpCount)
     - `DownCount` = SUM(各小时的 DownCount)
     - `TotalCount` = SUM(各小时的 TotalCount)
     - `SumDuration` = SUM(各小时的 SumDuration)
     - `AvgDuration` = SumDuration / UpCount（**加权平均**，确保准确性）
     - `MinDuration` = MIN(各小时的 MinDuration)
     - `MaxDuration` = MAX(各小时的 MaxDuration)
     - `Uptime` = UpCount * 10000 / TotalCount

3. **数据清理** (`cleanupAggregatedData`)
   - 清理超过 24 小时的原始心跳数据
   - 清理超过 7 天的小时聚合数据
   - 清理超过 365 天的日聚合数据

---

## 降采样对统计信息的影响

### 平均延迟计算规则

> **核心原则**：平均延迟只统计**成功响应(status=1)**的数据，去除失败响应的影响。

| 统计项 | 数据源 | 计算方式 |
|--------|--------|----------|
| **24小时平均延迟** | 原始数据 (Heartbeat) | `AVG(duration) WHERE status=1` |
| **7天平均延迟** | 小时聚合 (HeartbeatHourly) | `SUM(sum_duration) / SUM(up_count)` (加权平均) |
| **30天/更长平均延迟** | 日聚合 (HeartbeatDaily) | `SUM(sum_duration) / SUM(up_count)` (加权平均) |

**为什么使用加权平均？**

假设有两个小时的数据：
- 第1小时：UpCount=60, AvgDuration=100ms
- 第2小时：UpCount=10, AvgDuration=200ms

简单平均：`(100 + 200) / 2 = 150ms` ❌

加权平均：`(60*100 + 10*200) / (60+10) = (6000 + 2000) / 70 = 114.3ms` ✅

通过存储 `SumDuration` 字段，日聚合可以正确计算加权平均。

---

### 可用率计算规则

| 统计项 | 数据源 | 计算方式 |
|--------|--------|----------|
| **24小时内可用率** | 原始数据 (Heartbeat) | `UpCount / TotalCount * 100%` |
| **24小时/7天可用率** | 聚合数据 + 当前小时原始数据 | `SUM(UpCount) / SUM(TotalCount) * 100%` |
| **30天+可用率** | 日聚合数据 | `SUM(UpCount) / SUM(TotalCount) * 100%` |

**计算逻辑**：
1. 如果查询范围在原始数据保留期内（默认24小时），直接从 `Heartbeat` 表精确计算
2. 如果超出原始数据保留期：
   - 从 `HeartbeatHourly` 表获取已聚合时段的 `SUM(up_count)` 和 `SUM(total_count)`
   - 从 `Heartbeat` 表获取当前小时（尚未聚合）的数据
   - 合并计算：`(聚合UpCount + 当前UpCount) / (聚合TotalCount + 当前TotalCount) * 100%`

---

### 图表数据规则

#### 24小时图表

- **采样点数量**：24 个点
- **每个点粒度**：1 小时
- **数据源**：
  - 前 23 个点：从 `HeartbeatHourly` 表获取
  - 最后 1 个点（当前小时）：从原始 `Heartbeat` 表实时计算
- **显示数据**：
  - Duration = 该小时的 `AvgDuration`（只统计成功响应）
  - Status = 根据 `Uptime` 判断（<50% 显示为 DOWN）
  - Uptime = `Uptime / 100`（转换为百分比显示）

#### 7天图表

- **采样点数量**：28 个点
- **每个点粒度**：6 小时
- **数据源**：
  - 前 27 个点：从 `HeartbeatHourly` 表获取，每 6 条记录合并为 1 个采样点
  - 最后 1 个点（当前时段）：从原始 `Heartbeat` 表 + 已聚合数据合并计算
- **合并逻辑**：
  - Duration = 6 小时的 `AvgDuration` 简单平均
  - Uptime = `UpCount / (UpCount + DownCount) * 100%`
  - Status = 根据 Uptime 判断

---

## 配置项

在 `config.yaml` 中可以配置数据保留策略：

```yaml
retention:
  raw_hours: 24      # 原始数据保留 24 小时
  hourly_days: 7     # 小时聚合保留 7 天
  daily_days: 365    # 日聚合保留 1 年
```

---

## 数据库字段设计优化

为了节省存储空间，所有数值字段都使用 `int` 类型：

| 字段 | 类型 | 说明 |
|------|------|------|
| `UpCount` | int | UP 次数 |
| `DownCount` | int | DOWN 次数 |
| `TotalCount` | int | 总次数 |
| `SumDuration` | int | 成功响应延迟总和 (ms) |
| `AvgDuration` | int | 平均延迟 (ms) |
| `MinDuration` | int | 最小延迟 (ms) |
| `MaxDuration` | int | 最大延迟 (ms) |
| `Uptime` | int | 可用率 (0-10000 表示 0.00%-100.00%) |

> **注意**：`Uptime` 使用万分比存储，前端显示时需除以 100 转换为百分比。

---

## 智能查询层

系统会根据查询的时间范围自动选择最优数据源：

```go
func GetHeartbeatsWithTimeRange(monitorID uint, hours int) ([]map[string]any, string) {
    if hours <= 24 {
        // 24小时内：查询原始数据 (最高精度)
        return getRawHeartbeats(monitorID, hours), "raw"
    } else if hours <= 24*7 {
        // 7天内：查询小时聚合数据
        return getHourlyHeartbeats(monitorID, hours), "hourly"
    } else {
        // 7天以上：查询日聚合数据
        return getDailyHeartbeats(monitorID, hours), "daily"
    }
}
```

---

## 总结

### 核心改进

1. **平均延迟只统计成功响应**：去除失败响应（通常是超时或连接失败）对平均延迟的影响
2. **使用加权平均**：通过存储 `SumDuration` 确保多级聚合后的平均值准确
3. **数据库字段精简**：将 `float64` 改为 `int`，节省存储空间
4. **分层存储**：三级数据层确保近期高精度、远期低成本

### 数据流转图

```
原始心跳数据 (每20-60秒)
    │
    │ 每小时聚合
    ▼
小时聚合数据 (HeartbeatHourly)
    │
    │ 每天聚合
    ▼
日聚合数据 (HeartbeatDaily)
    │
    │ 定期清理
    ▼
过期数据删除
```

### 清理策略

- 原始数据：保留 24 小时后删除
- 小时数据：保留 7 天后删除
- 日数据：保留 365 天后删除